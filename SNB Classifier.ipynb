{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c863526b-a4c4-4d56-ade9-309a5b3e2cb0",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Representation\n",
    "I have chosen to model the data using dictionaries inside a dictionary. This is done for me by the get_word_statistics(targets) function which also counts all the necessary calculations I need to eventually calculate posterior probabilities eg. class frequencies, unique words in a class etc. The resulting dictionary has every word that appears in the full dataset mapping to a dictionary with the frequency of that word in each class. For example, the word \"the\" : {'B':18145,'A':1783,'E':24794,'V':1785} optimising runtime. Rather than using 0-1 attributes, I used the frequencies of the words as it improves the accuracy of the model since it means the words are weighted, meaning the probabilities are tuned to be more accurate. This is also very useful in regards to extending the implementation for better accuracy, as we can weight the words giving more frequent words appearing more significance. A binary classifier would cause a lot of information loss. Using frequencies rather than a binary approach can increase the runtime but since my representation of the data is collected efficiently, it did not make a big difference for me. I chose to represent the data in a dictionary rather than something such as a dataframe which I had also considered, because the complexity became very large using a dataframe such as CountVectorizer. The dictionary representation is very efficient and computationally minimal and does not require me to import many different packages and libraries, keeping the code simple but effective and consuming much less memory than a dataframe would. \n",
    "# Implementation & Improvement\n",
    "I implemented the SNB by calling the get_word_statistics() and passing it the trg.csv file content. This generated the dictionary I needed for all my calculations, as well as the variables I need for calculations. I implemented a method called conditional calculates the conditional probability for a word appearing in a specific class using laplace smoothing which prevents 0 probabilities as well as overfitting of the data. I also implemented a posterior method which calculates the posterior probability for a class label and an abstract. Lastly I used a method called testing which takes one argument which is the test data. This runs the process of the SNB making class predictions. I tested my SND using tst.csv data as you can see below. I extended this model using the concept of data cleaning. Data cleaning can be done in different ways, eg.lowercasing or concatenating words etc. I have chosen to implement data cleaning by removing stop-words. Stop-words are words that are insignificant to the context of the data, such as \"and\". I made a dataclean() method to implement the extension of my SNB. I chose to do this since in my original word frequency I noticed the word \"and\" is one of the most common words to appear in this given dataset so I felt that the accuracy would improve by getting rid of these stopwords, such as \"and\". Data cleaning is an important part of preprocessing the data and by removing stopwords we decrease bias, and increase the accuracy as well as reducing overfitting of the dataset (counting evidence twice when it's just one piece of evidence). I could have further implemented the classifier by doing other forms of preprocessing but I was interested in seeing how much the accuracy would change from just removing stopwords since they were so frequent in the data. This is implemented in the dataclean() function I made.\n",
    "# Evaluation\n",
    "To evaluate the procedure I used cross-validation. I used a 5-fold cross validation as a 10-fold cross validation does not improve the accuracy much but increases the runtime a lot which means the classifier becomes very computationally consumptive. Training/validation split works by splitting the data up into a training set and validation set just once whereas cross-validation splits the data up multiple times and evaluates the accuracy by averaging the accuracies. This reduces optimisation bias and gives a better approximation of the accuracy which is why I chose to use cross-validation rather than training/validation split. The accuracy for the SNB classifier was 0.981, 98.1% whereas the accuracy for the extended implementation of the naive bayes classifier was 0.982, 98.2% This improvement in accuracy is very small despite what I thought would happen. I assume this is because the accuracy of the SNB implementation was already considerably high which means it is hard to improve such a high accuracy with just one form of data cleaning. To improve the accuracy more, I would need to implement more extensive data cleaning, and even consider implementing other improvements such as n-grams. However, we can still see the improvement in removing stop-words from the dataset, such small improvements add up in large datasets such as the one provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "10f89a99-f41b-4bb1-9199-829ff48969a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 1\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "targets_read = pd.read_csv(\"datasets/trg.csv\")\n",
    "test_read = pd.read_csv(\"datasets/tst.csv\")\n",
    "\n",
    "\n",
    "\n",
    "labels = (targets_read[\"class\"].unique()) #labels A,E,B,V\n",
    "counting = targets_read[\"class\"].value_counts().to_dict() # frequencies of the classes\n",
    "\n",
    "\n",
    "prior_probs = {key: math.log(value) - math.log(sum(counting.values())) for key, value in counting.items()} #prior log probabilities\n",
    "class_counts = targets_read[\"class\"].value_counts(normalize=True).to_dict() #class frequencies \n",
    "\n",
    "\n",
    "def get_word_statistics(targets): #generates word frequency dictionary and other variables\n",
    "    global word_frequencies, total_words_in_class, unique_words_in_class #allows access outside the function of the variables \n",
    "    \n",
    "    for index, row in targets.iterrows():\n",
    "        unique_words = set()\n",
    "        \n",
    "        for word in row[\"abstract\"].split():\n",
    "            unique_words.add(word)\n",
    "            \n",
    "            try:\n",
    "                total_words_in_class[row[\"class\"]] += 1         #counting total words in the particular class\n",
    "            except:\n",
    "                total_words_in_class[row[\"class\"]] = 1\n",
    "            \n",
    "            try:\n",
    "                try:\n",
    "                    word_frequencies[word][row[\"class\"]] += 1   #counting frequency of a word in a particular class\n",
    "                except:\n",
    "                    word_frequencies[word][row[\"class\"]] = 1\n",
    "            except:\n",
    "                word_frequencies[word] = {row[\"class\"]: 1}\n",
    "\n",
    "        try:\n",
    "            unique_words_in_class[row[\"class\"]].update(unique_words)\n",
    "        except:\n",
    "            unique_words_in_class[row[\"class\"]] = unique_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "de625af1-73e4-4dad-9774-286af42bb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 1\n",
    "word_frequencies = {}\n",
    "total_words_in_class = {}\n",
    "unique_words_in_class = {}\n",
    "get_word_statistics(targets_read)\n",
    "total_unique = len(word_frequencies.keys())\n",
    "#print(word_frequencies) #run this to see the data representation output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "9bb6fdc2-a257-468b-9788-b0e2779c2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 2\n",
    "\n",
    "def conditional(label, word):\n",
    "    if word in word_frequencies:\n",
    "        try:\n",
    "            word_count = word_frequencies[word][label] + 1 #laplace smoothing\n",
    "        except KeyError:\n",
    "            word_count = 1    # in case word of the test code is not in the training data\n",
    "    else:\n",
    "        word_count = 1 \n",
    "    total_class_count = total_words_in_class[label] + total_unique #laplace smoothing for when probability is 0 \n",
    "                                                                   #eg. the word is not in the training data when testing\n",
    "    \n",
    "    numerator = math.log(word_count) \n",
    "    denominator = math.log(total_class_count)\n",
    "    result = numerator - denominator  #log(a/b) = log(a) - log(b)\n",
    "    return result \n",
    "\n",
    "def posterior(words, label):\n",
    "    probabilities = []\n",
    "    for w in words:\n",
    "        probabilities += [conditional(label, w)]    #log(a*b) = log(a) + log(b)\n",
    "    return sum(probabilities) + prior_probs[label]  #log(a*b) = log(a) + log(b)\n",
    "    \n",
    "def testing(test_data):\n",
    "    test_list = test_data.to_numpy()\n",
    "    predictions = {}\n",
    "    for item in test_list:\n",
    "\n",
    "        i_d = item[0]\n",
    "        content = item[1].split()\n",
    "        probs = {}\n",
    "        for l in labels:\n",
    "            probs[l] = posterior(content, l) \n",
    "\n",
    "        maximum = {}\n",
    "        for l in labels:\n",
    "            maximum[l] = probs[l] + probs[l] - sum(value for value in probs.values()) #calculating posterior probability in log space\n",
    "\n",
    "        predictions[i_d]= max(maximum, key = probs.get)\n",
    "    return predictions\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "d8ef38ca-893a-4ed2-ad86-ebe4348621a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 2 code running for naive standard bayes on tst.csv\n",
    "word_frequencies = {}\n",
    "total_words_in_class = {}\n",
    "unique_words_in_class = {}\n",
    "get_word_statistics(targets_read)\n",
    "total_unique = len(word_frequencies.keys())\n",
    "#print(testing(test_read)) run this to see the output of the predictions!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "24fa32bf-3f72-4941-8f91-9cee4f4bbf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataclean(content):\n",
    "    words = content.split()\n",
    "    new_abstr = []\n",
    "    for w in words:\n",
    "        if (w not in set(stopwords.words(\"english\"))): \n",
    "            new_abstr+=[w] #only adding words that are NOT stopwords\n",
    "    \n",
    "    return ' '.join(new_abstr) #returning abstract without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "0e6152c7-ed01-4000-8fd0-064801b21391",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = targets_read.copy()\n",
    "cleaned[\"abstract\"] = cleaned['abstract'].apply(dataclean)\n",
    "word_frequencies = {}\n",
    "total_words_in_class = {}\n",
    "unique_words_in_class = {}\n",
    "get_word_statistics(cleaned)\n",
    "total_unique = len(word_frequencies.keys())\n",
    "#print(word_frequencies) run this to see the output of the cleaned data representation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "ef45057c-7b64-42f6-af86-ee1229c7d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 3 \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def cross_validation(raw):\n",
    "\n",
    "    average = 0\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        word_frequencies = {}\n",
    "        total_words_in_class = {}\n",
    "        unique_words_in_class = {}  \n",
    "    \n",
    "        training_data = raw.sample(frac=0.8, random_state=22) #selecting random 80% of the data\n",
    "        index = training_data.index #finding index of the 80% training data\n",
    "        validation_data = raw.drop(index) #assigning validation_data to remaining 20% of the data\n",
    "    \n",
    "        labels = training_data[\"class\"].unique()\n",
    "        \n",
    "        counting = training_data[\"class\"].value_counts().to_dict()\n",
    "        \n",
    "        prior_probs = {key: math.log(value) - math.log(sum(counting.values())) for key, value in counting.items()}\n",
    "        class_counts = training_data[\"class\"].value_counts(normalize=True).to_dict() \n",
    "\n",
    "        #preliminary calculations used to calculate posterior probability\n",
    "    \n",
    "        get_word_statistics(training_data)     #training the data\n",
    "        total_unique = len(word_frequencies.keys())\n",
    "    \n",
    "        validate = validation_data.drop(columns=['class'])  \n",
    "        predicted_classes = testing(validate)      #testing validation data on the model trained by the training data\n",
    "    \n",
    "        correct = 0\n",
    "        \n",
    "        actual_classes = {}\n",
    "        for index, row in validation_data.iterrows():\n",
    "            actual_classes[ row[\"id\"] ] = row[\"class\"]\n",
    "    \n",
    "        for id_ , predicted_class in predicted_classes.items():\n",
    "            if actual_classes[id_] == predicted_class:\n",
    "                correct += 1\n",
    "        average+=(correct/len(predicted_classes))        #calculating accuracy\n",
    "    \n",
    "    average = average/i    \n",
    "    return average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "70ab64e7-9e08-4253-b9fa-5914f76fb4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy when using a 5-fold cross-validation on the standard Naive Bayes implementation is 0.981\n"
     ]
    }
   ],
   "source": [
    "targets_read = pd.read_csv(\"datasets/trg.csv\")\n",
    "standard = targets_read.copy()\n",
    "print(\"The average accuracy when using a 5-fold cross-validation on the standard Naive Bayes implementation is {:.3f}\".format(cross_validation(standard)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "89e7233e-0297-4561-9055-3ee3ade4266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy when using a 5-fold cross-validation on the extended Naive Bayes implementation is 0.982\n"
     ]
    }
   ],
   "source": [
    "cleaned = targets_read.copy()\n",
    "cleaned[\"abstract\"] = cleaned['abstract'].apply(dataclean)\n",
    "word_frequencies = {}\n",
    "total_words_in_class = {}\n",
    "unique_words_in_class = {}\n",
    "get_word_statistics(cleaned)\n",
    "total_unique = len(word_frequencies.keys())\n",
    "print(\"The average accuracy when using a 5-fold cross-validation on the extended Naive Bayes implementation is {:.3f}\".format(cross_validation(cleaned)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
